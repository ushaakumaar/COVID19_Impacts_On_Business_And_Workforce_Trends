{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Github Setup\n",
    "   1. Create a branch with below mentioned names (git checkout -b branch_name)\n",
    "       -> unemployment\n",
    "       -> business-profit-loss\n",
    "       -> safest-travel-route\n",
    "       -> airlines\n",
    "       -> mobility\n",
    "   2. Clone the branch to your local directory\n",
    "   3. Create Resources & Output folders in your local directory inside your repository\n",
    "   4. Create a jupyter notebook file directly under branch\n",
    "   5. Push these folders and file to github branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment\n",
    "    1. Go to https://data.bls.gov/cgi-bin/surveymost?ln\n",
    "    2. Select the following\n",
    "       Unemployment Rate - LNS14000000\n",
    "       Unemployment Rate - White - LNS14000003\n",
    "       Unemployment Rate - Black or African American - LNS14000006\n",
    "       Unemployment Rate - Asian - LNS14032183\n",
    "       Unemployment Rate - Hispanic or Latino - LNS14000009\n",
    "    3. Click Retrieve Data\n",
    "    4. Download each xlsx\n",
    "    5. Repeat the same for the rest of the Datasets\n",
    "       https://beta.bls.gov/dataQuery/find?st=0&r=20&q=unemployment&more=0&fq=cg:[Unemployment+and+Labor+Force+Status]\n",
    "       https://beta.bls.gov/dataQuery/find?st=0&r=20&q=unemployment&more=0&fq=cg:[Establishments%2FBusinesses%2FFirms]\n",
    "       https://beta.bls.gov/dataQuery/find?st=0&r=20&q=unemployment&more=0&fq=cg:[Geography]\n",
    "    5. You could extract a subset of csvs for states/businesses to begin your logic and extract all data and expand the code\n",
    "    6. Put all the csvs/xlsx in Resources folder and push to Github branch\n",
    "    7. Code to read each file and extract the unemployment rate into individual series\n",
    "    8. Create five dataframes (Ethnicity/race/gender/businesses/states) with the unemployment rates\n",
    "    9. Group by and determine min and max for each group\n",
    "    10. Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business-profit-loss (Usha and Chahnaz)\n",
    "    1. Run the kaggle script to get the latest data (Usha)\n",
    "    2. Extract just the data for Dec 31 2019 and Last available Date for each Business and save it in a Dataframe (Usha)\n",
    "    \n",
    "    3. Perform Data Cleanup - Lookout for null/duplicate values in data (Chahnaz)\n",
    "    4. Calculations to see if the value of each business has gone up or down (Chahnaz)\n",
    "    \n",
    "    5. Find the business that has most profit/most loss (Usha)\n",
    "    \n",
    "    6. Plot 1 the profit/losses of all businesses (Chahnaz)\n",
    "    7  Plot 2 (Usha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safest-travel-route\n",
    "    1. Extract the county wise covid data from https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\n",
    "    2. Extract the county wise population data from https://covid19.census.gov/datasets/population-by-age-and-sex-counties?selectedAttribute=B01001_001E\n",
    "    3. Create Dataframe with Countyname, Statename, Population, Covid count, Death Count\n",
    "    4. Perform Data Cleanup - Lookout for null/duplicate values in data\n",
    "    5. Create a new column \"Count per Thousand\" -> (Covid count/Population)\n",
    "    6. Create a new column \"Death per Thousand\" -> (Covid count/Population)\n",
    "    7. Plot the county wise count and death data\n",
    "    8. Determine the county/city with least \"Count per Thousand\" / \"Death per Thousand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines\n",
    "    1. Extract airlines data from https://www.kaggle.com/akulbahl/covid19-airline-flight-delays-and-cancellations\n",
    "    2. Create a Dataframe with columns we will need alone - \n",
    "        YEAR, \n",
    "        MONTH, \n",
    "        FL_DATE, \n",
    "        MKT_UNIQUE_CARRIER, \n",
    "        ORIGIN, \n",
    "        ORIGIN_CITY_NAME, \n",
    "        DEST, \n",
    "        DEST_CITY_NAME, \n",
    "        CANCELLED,\n",
    "        CANCELLATION_CODE,\n",
    "        DEP_DELAY,\n",
    "        ARR_DELAY,\n",
    "        CARRIER_DELAY,\n",
    "        WEATHER_DELAY,\n",
    "        NAS_DELAY,\n",
    "        SECURITY_DELAY,\n",
    "        LATE_AIRCRAFT_DELAY\n",
    "    3. Perform Data Cleanup - Lookout for null/duplicate values in data\n",
    "    4. Steps to determine most affected travel route\n",
    "        i. Group by origin, dest and find sum() for cancelled, delay columns\n",
    "        ii. Determine the route which has max() cancellations/delays to determine most affected route\n",
    "    5. Steps to determine most affected airline\n",
    "        i. Group by mkt_unique_carrier and find sum() for cancelled, delay columns\n",
    "        ii. Determine the airline which has max() cancellations/delays to determine most affected airline\n",
    "    6. Plot the origin/dest against the cancellation counts\n",
    "    7. Plot the airlines against the cancellation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility\n",
    "    1. Extract data from https://data.bts.gov/Research-and-Statistics/Trips-by-Distance/w96p-f2qv using API\n",
    "    2. Create a Dataframe with columns we will need alone - \n",
    "        Date,\n",
    "        State Postal Code,\n",
    "        County Name,\n",
    "        Population Staying at Home,\n",
    "        Population Not Staying at Home\n",
    "    2. Extract data from https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\n",
    "    3. Create a dataframe with columns we will need alone - \n",
    "        Date,\n",
    "        State,\n",
    "        County,\n",
    "        Cases,\n",
    "        Deaths\n",
    "    4. Merge the two Dataframes using Date, State and County names to have the following columns in resulting Dataframe\n",
    "        Date,\n",
    "        State,\n",
    "        County,\n",
    "        Population Staying at Home,\n",
    "        Population Not Staying at Home,\n",
    "        Cases,\n",
    "        Deaths\n",
    "    5. Scatter Plot and check correlation between covid cases and population staying at home\n",
    "    6. Map with the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
